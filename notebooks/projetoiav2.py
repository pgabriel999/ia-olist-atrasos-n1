# -*- coding: utf-8 -*-
"""projetoIAV2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cve3Md8ij8JglWSUJba9fJ3FGDtU5Qsm
"""

# =============================================================================
# PROJETO IA - AN√ÅLISE DE ATRASOS E SATISFA√á√ÉO NO E-COMMERCE BRASILEIRO
# Membros: Pedro Gabriel Marotta Silva - RA: 10418073 / Agozie Nunes Emehelu RA:10403570
# Dataset: Brazilian E-Commerce Public Dataset by Olist
# Objetivo: Processar dados para an√°lise de atrasos de entrega e reviews (N1)
# =============================================================================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# Configurar visualiza√ß√µes
plt.style.use('default')
sns.set_palette("husl")

print("=== PROJETO IA - AN√ÅLISE DE E-COMMERCE BRASILEIRO ===")
print("Autor: [Pedro Gabriel Marotta Silva e Agozie Nunes Emehelu]")
print("Data:", datetime.now().strftime("%d/%m/%Y %H:%M"))
print("Disciplina: Intelig√™ncia Artificial - 7¬∫J SI")
print("="*60)

# =============================================================================
# 1. CARREGAR DADOS
# =============================================================================

def load_olist_data():
    """
    Carrega todos os datasets do Olist do diret√≥rio /content/
    Retorna dicion√°rio com todos os DataFrames
    """
    try:
        print("\nüìÅ Carregando datasets...")

        data = {}
        files = {
            'customers': 'olist_customers_dataset.csv',
            'geolocation': 'olist_geolocation_dataset.csv',
            'order_items': 'olist_order_items_dataset.csv',
            'order_payments': 'olist_order_payments_dataset.csv',
            'order_reviews': 'olist_order_reviews_dataset.csv',
            'orders': 'olist_orders_dataset.csv',
            'products': 'olist_products_dataset.csv',
            'sellers': 'olist_sellers_dataset.csv',
            'category_translation': 'product_category_name_translation.csv'
        }

        for key, filename in files.items():
            data[key] = pd.read_csv(f'/content/{filename}')
            print(f"‚úÖ {filename}: {len(data[key])} registros")

        print(f"\nüéâ Total: {len(data)} datasets carregados com sucesso!")
        return data

    except FileNotFoundError as e:
        print(f"‚ùå Erro: {e}")
        print("\nüîç INSTRU√á√ïES:")
        print("1. Fa√ßa upload dos arquivos CSV para /content/")
        print("2. Ou use: from google.colab import files; files.upload()")
        return None

# =============================================================================
# 2. AN√ÅLISE EXPLORAT√ìRIA INICIAL
# =============================================================================

def exploratory_analysis(data):
    """
    Realiza an√°lise explorat√≥ria inicial dos dados
    """
    print("\n" + "="*60)
    print("üìä AN√ÅLISE EXPLORAT√ìRIA INICIAL")
    print("="*60)

    summary_data = []

    for name, df in data.items():
        missing_pct = (df.isnull().sum().sum() / (len(df) * len(df.columns))) * 100

        print(f"\nüìã Dataset: {name.upper()}")
        print(f"   ‚Ä¢ Linhas: {len(df):,}")
        print(f"   ‚Ä¢ Colunas: {len(df.columns)}")
        print(f"   ‚Ä¢ Dados faltantes: {missing_pct:.1f}%")
        print(f"   ‚Ä¢ Colunas: {', '.join(df.columns[:5])}{'...' if len(df.columns) > 5 else ''}")

        summary_data.append({
            'Dataset': name,
            'Registros': len(df),
            'Colunas': len(df.columns),
            'Missing_Pct': round(missing_pct, 1)
        })

    # Criar resumo
    summary_df = pd.DataFrame(summary_data)
    summary_df.to_csv('/content/dataset_summary.csv', index=False)

    return summary_df

# =============================================================================
# 3. PROCESSAMENTO PRINCIPAL - ATRASOS E REVIEWS
# =============================================================================

def process_delivery_analysis(data):
    """
    Processa dados para an√°lise de atrasos de entrega e satisfa√ß√£o
    Foco: identificar padr√µes de atraso e impacto nas avalia√ß√µes
    """
    print("\n" + "="*60)
    print("üîÑ PROCESSANDO DADOS PARA AN√ÅLISE DE ATRASOS")
    print("="*60)

    orders = data['orders'].copy()
    reviews = data['order_reviews'].copy()

    # 1. Processar datas
    print("\nüìÖ Processando datas...")
    date_cols = ['order_purchase_timestamp', 'order_approved_at',
                'order_delivered_carrier_date', 'order_delivered_customer_date',
                'order_estimated_delivery_date']

    for col in date_cols:
        if col in orders.columns:
            orders[col] = pd.to_datetime(orders[col], errors='coerce')

    # 2. Calcular m√©tricas de entrega
    print("‚è∞ Calculando m√©tricas de tempo...")

    # Tempo total de entrega (compra ‚Üí entrega)
    orders['delivery_time_days'] = (
        orders['order_delivered_customer_date'] - orders['order_purchase_timestamp']
    ).dt.days

    # Atraso em dias (real vs estimado)
    orders['delay_days'] = (
        orders['order_delivered_customer_date'] - orders['order_estimated_delivery_date']
    ).dt.days

    # Classificar atraso
    orders['delay_category'] = orders['delay_days'].apply(
        lambda x: 'Muito Atrasado' if x > 7 else
                 'Atrasado' if x > 0 else
                 'No Prazo' if x >= -3 else
                 'Antecipado' if not pd.isna(x) else 'Sem Info'
    )

    # 3. Merge com reviews
    print("üîó Conectando com avalia√ß√µes...")
    delivery_analysis = pd.merge(
        orders[['order_id', 'order_status', 'delivery_time_days', 'delay_days', 'delay_category']],
        reviews[['order_id', 'review_score', 'review_comment_message']],
        on='order_id',
        how='left'
    )

    # 4. Filtrar apenas pedidos entregues com dados completos
    delivery_analysis = delivery_analysis[
        (delivery_analysis['order_status'] == 'delivered') &
        (delivery_analysis['delay_days'].notna()) &
        (delivery_analysis['review_score'].notna())
    ].copy()

    print(f"‚úÖ Dataset final: {len(delivery_analysis):,} pedidos com dados completos")

    return delivery_analysis

# =============================================================================
# 4. AN√ÅLISES ESTAT√çSTICAS PARA O RELAT√ìRIO
# =============================================================================

def generate_report_statistics(delivery_data):
    """
    Gera estat√≠sticas essenciais para o relat√≥rio N1
    """
    print("\n" + "="*60)
    print("üìà GERANDO ESTAT√çSTICAS PARA RELAT√ìRIO")
    print("="*60)

    results = {}

    # 1. ESTAT√çSTICAS GERAIS
    print("\n1Ô∏è‚É£ Estat√≠sticas Gerais:")
    total_orders = len(delivery_data)
    avg_delivery_time = delivery_data['delivery_time_days'].mean()
    avg_delay = delivery_data['delay_days'].mean()
    avg_review_score = delivery_data['review_score'].mean()

    general_stats = {
        'total_pedidos': total_orders,
        'tempo_entrega_medio_dias': round(avg_delivery_time, 1),
        'atraso_medio_dias': round(avg_delay, 1),
        'nota_media_review': round(avg_review_score, 2)
    }

    for key, value in general_stats.items():
        print(f"   ‚Ä¢ {key}: {value:,}")

    results['general_stats'] = pd.DataFrame([general_stats])

    # 2. AN√ÅLISE POR CATEGORIA DE ATRASO
    print("\n2Ô∏è‚É£ An√°lise por Categoria de Atraso:")
    delay_analysis = delivery_data.groupby('delay_category').agg({
        'order_id': 'count',
        'review_score': ['mean', 'std'],
        'delay_days': ['mean', 'min', 'max']
    }).round(2)

    delay_analysis.columns = ['qtd_pedidos', 'review_media', 'review_std',
                             'delay_medio', 'delay_min', 'delay_max']
    delay_analysis['percentual'] = (delay_analysis['qtd_pedidos'] / total_orders * 100).round(1)

    print(delay_analysis)
    results['delay_analysis'] = delay_analysis

    # 3. CORRELA√á√ÉO ATRASO vs SATISFA√á√ÉO
    print("\n3Ô∏è‚É£ Correla√ß√£o Atraso vs Satisfa√ß√£o:")
    correlation = delivery_data['delay_days'].corr(delivery_data['review_score'])
    print(f"   ‚Ä¢ Correla√ß√£o delay_days vs review_score: {correlation:.3f}")

    # 4. DISTRIBUI√á√ÉO DE REVIEWS POR FAIXA DE ATRASO
    print("\n4Ô∏è‚É£ Reviews por Faixa de Atraso:")
    review_distribution = pd.crosstab(
        delivery_data['delay_category'],
        delivery_data['review_score'],
        normalize='index'
    ).round(3) * 100

    print("Distribui√ß√£o percentual de notas por categoria:")
    print(review_distribution)
    results['review_distribution'] = review_distribution

    # 5. ESTAT√çSTICAS PARA MODELAGEM (N2)
    print("\n5Ô∏è‚É£ Preparando para Modelagem:")

    # Criar target bin√°rio para classifica√ß√£o: review ruim (1-3) vs boa (4-5)
    delivery_data['review_ruim'] = (delivery_data['review_score'] <= 3).astype(int)

    # Estat√≠sticas do target
    review_ruim_stats = delivery_data['review_ruim'].value_counts()
    print(f"   ‚Ä¢ Reviews ruins (1-3): {review_ruim_stats[1]:,} ({review_ruim_stats[1]/len(delivery_data)*100:.1f}%)")
    print(f"   ‚Ä¢ Reviews boas (4-5): {review_ruim_stats[0]:,} ({review_ruim_stats[0]/len(delivery_data)*100:.1f}%)")

    results['model_target_stats'] = pd.DataFrame({
        'categoria': ['Review Ruim (1-3)', 'Review Boa (4-5)'],
        'quantidade': [review_ruim_stats[1], review_ruim_stats[0]],
        'percentual': [review_ruim_stats[1]/len(delivery_data)*100,
                      review_ruim_stats[0]/len(delivery_data)*100]
    })

    return results, delivery_data

# =============================================================================
# 5. VISUALIZA√á√ïES PARA O RELAT√ìRIO
# =============================================================================

def create_visualizations(delivery_data, results):
    """
    Cria visualiza√ß√µes essenciais para o relat√≥rio
    """
    print("\n" + "="*60)
    print("üìä CRIANDO VISUALIZA√á√ïES")
    print("="*60)

    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('An√°lise de Atrasos e Satisfa√ß√£o - E-commerce Brasileiro', fontsize=16, fontweight='bold')

    # 1. Distribui√ß√£o de Atrasos
    axes[0,0].hist(delivery_data['delay_days'], bins=50, edgecolor='black', alpha=0.7)
    axes[0,0].axvline(0, color='red', linestyle='--', label='Prazo Estimado')
    axes[0,0].set_title('Distribui√ß√£o de Atrasos de Entrega')
    axes[0,0].set_xlabel('Atraso (dias)')
    axes[0,0].set_ylabel('Frequ√™ncia')
    axes[0,0].legend()
    axes[0,0].grid(True, alpha=0.3)

    # 2. Review Score por Categoria de Atraso
    delay_review = delivery_data.groupby('delay_category')['review_score'].mean().sort_values()
    axes[0,1].bar(range(len(delay_review)), delay_review.values, color='skyblue', edgecolor='black')
    axes[0,1].set_xticks(range(len(delay_review)))
    axes[0,1].set_xticklabels(delay_review.index, rotation=45)
    axes[0,1].set_title('Nota M√©dia por Categoria de Atraso')
    axes[0,1].set_ylabel('Review Score M√©dio')
    axes[0,1].grid(True, alpha=0.3)

    # 3. Correla√ß√£o Atraso vs Review
    axes[1,0].scatter(delivery_data['delay_days'], delivery_data['review_score'],
                     alpha=0.5, s=1, color='coral')
    axes[1,0].set_title('Correla√ß√£o: Atraso vs Review Score')
    axes[1,0].set_xlabel('Atraso (dias)')
    axes[1,0].set_ylabel('Review Score')
    axes[1,0].grid(True, alpha=0.3)

    # Linha de tend√™ncia
    z = np.polyfit(delivery_data['delay_days'], delivery_data['review_score'], 1)
    p = np.poly1d(z)
    axes[1,0].plot(delivery_data['delay_days'], p(delivery_data['delay_days']),
                  "r--", alpha=0.8, linewidth=2)

    # 4. Distribui√ß√£o de Review Scores
    review_counts = delivery_data['review_score'].value_counts().sort_index()
    axes[1,1].bar(review_counts.index, review_counts.values, color='lightgreen', edgecolor='black')
    axes[1,1].set_title('Distribui√ß√£o de Review Scores')
    axes[1,1].set_xlabel('Review Score')
    axes[1,1].set_ylabel('Quantidade')
    axes[1,1].grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig('/content/analise_atrasos_satisfacao.png', dpi=300, bbox_inches='tight')
    plt.show()

    print("‚úÖ Gr√°fico salvo como: analise_atrasos_satisfacao.png")

# =============================================================================
# 6. EXPORTAR RESULTADOS
# =============================================================================

def export_results(delivery_data, results):
    """
    Exporta todos os resultados em arquivos CSV para uso no relat√≥rio
    """
    print("\n" + "="*60)
    print("üíæ EXPORTANDO RESULTADOS")
    print("="*60)

    # 1. Dataset principal processado
    delivery_data.to_csv('/content/dataset_processado_atrasos.csv', index=False)
    print("‚úÖ dataset_processado_atrasos.csv")

    # 2. Estat√≠sticas gerais
    results['general_stats'].to_csv('/content/estatisticas_gerais.csv', index=False)
    print("‚úÖ estatisticas_gerais.csv")

    # 3. An√°lise por categoria de atraso
    results['delay_analysis'].to_csv('/content/analise_por_categoria_atraso.csv')
    print("‚úÖ analise_por_categoria_atraso.csv")

    # 4. Distribui√ß√£o de reviews
    results['review_distribution'].to_csv('/content/distribuicao_reviews_por_atraso.csv')
    print("‚úÖ distribuicao_reviews_por_atraso.csv")

    # 5. Stats para modelagem
    results['model_target_stats'].to_csv('/content/target_modelagem_stats.csv', index=False)
    print("‚úÖ target_modelagem_stats.csv")

    # 6. Resumo executivo para relat√≥rio
    summary_report = f"""
RESUMO EXECUTIVO - AN√ÅLISE DE ATRASOS E SATISFA√á√ÉO
Dataset: Brazilian E-Commerce Public Dataset by Olist
Data da An√°lise: {datetime.now().strftime("%d/%m/%Y %H:%M")}

PRINCIPAIS DESCOBERTAS:
‚Ä¢ Total de pedidos analisados: {len(delivery_data):,}
‚Ä¢ Tempo m√©dio de entrega: {delivery_data['delivery_time_days'].mean():.1f} dias
‚Ä¢ Atraso m√©dio: {delivery_data['delay_days'].mean():.1f} dias
‚Ä¢ Nota m√©dia geral: {delivery_data['review_score'].mean():.2f}
‚Ä¢ Correla√ß√£o atraso vs satisfa√ß√£o: {delivery_data['delay_days'].corr(delivery_data['review_score']):.3f}

DISTRIBUI√á√ÉO DE ATRASOS:
{results['delay_analysis']['percentual'].to_string()}

IMPACTO NA SATISFA√á√ÉO:
‚Ä¢ Reviews ruins (1-3): {(delivery_data['review_score'] <= 3).sum():,} ({(delivery_data['review_score'] <= 3).mean()*100:.1f}%)
‚Ä¢ Reviews boas (4-5): {(delivery_data['review_score'] >= 4).sum():,} ({(delivery_data['review_score'] >= 4).mean()*100:.1f}%)

RECOMENDA√á√ïES PARA MODELAGEM (N2):
1. Usar 'delay_days' como feature principal para previs√£o de atraso
2. Target bin√°rio: review_ruim (score 1-3) vs review_boa (score 4-5)
3. Features adicionais: delivery_time_days, sazonalidade, geolocaliza√ß√£o
4. Algoritmos sugeridos: Random Forest, Gradient Boosting, Logistic Regression
    """

    with open('/content/resumo_executivo.txt', 'w', encoding='utf-8') as f:
        f.write(summary_report)
    print("‚úÖ resumo_executivo.txt")

    print(f"\nüéâ Todos os arquivos exportados para /content/")
    print("üìÅ Arquivos gerados:")
    print("   ‚Ä¢ dataset_processado_atrasos.csv (dados limpos para N2)")
    print("   ‚Ä¢ estatisticas_gerais.csv (n√∫meros-chave)")
    print("   ‚Ä¢ analise_por_categoria_atraso.csv (tabela principal)")
    print("   ‚Ä¢ distribuicao_reviews_por_atraso.csv (crosstab)")
    print("   ‚Ä¢ target_modelagem_stats.csv (balanceamento do target)")
    print("   ‚Ä¢ analise_atrasos_satisfacao.png (gr√°ficos)")
    print("   ‚Ä¢ resumo_executivo.txt (s√≠ntese para relat√≥rio)")

# =============================================================================
# 7. EXECU√á√ÉO PRINCIPAL
# =============================================================================

def main():
    """
    Fun√ß√£o principal - executa todo o pipeline de an√°lise
    """
    try:
        # 1. Carregar dados
        data = load_olist_data()
        if data is None:
            return

        # 2. An√°lise explorat√≥ria
        summary = exploratory_analysis(data)

        # 3. Processamento principal
        delivery_data = process_delivery_analysis(data)

        # 4. Estat√≠sticas para relat√≥rio
        results, delivery_data_final = generate_report_statistics(delivery_data)

        # 5. Visualiza√ß√µes
        create_visualizations(delivery_data_final, results)

        # 6. Exportar resultados
        export_results(delivery_data_final, results)

        print("\n" + "="*60)
        print("üéâ AN√ÅLISE CONCLU√çDA COM SUCESSO!")
        print("="*60)
        print("‚úÖ Dados processados e exportados")
        print("‚úÖ Visualiza√ß√µes criadas")
        print("‚úÖ Relat√≥rios gerados")
        print("\nüìù Pr√≥ximos passos:")
        print("1. Baixe os arquivos CSV gerados")
        print("2. Use os dados no seu relat√≥rio N1")
        print("3. Para N2: implemente modelos de ML com dataset_processado_atrasos.csv")

    except Exception as e:
        print(f"‚ùå Erro durante execu√ß√£o: {e}")
        print("üîç Verifique se todos os arquivos CSV foram carregados corretamente")

# EXECUTAR AN√ÅLISE
if __name__ == "__main__":
    main()

# Execute para baixar todos os arquivos gerados
from google.colab import files
import zipfile

# Criar ZIP com todos os resultados
with zipfile.ZipFile('/content/resultados_projeto_ia.zip', 'w') as zipf:
    files_to_zip = [
        'dataset_processado_atrasos.csv',
        'estatisticas_gerais.csv',
        'analise_por_categoria_atraso.csv',
        'distribuicao_reviews_por_atraso.csv',
        'target_modelagem_stats.csv',
        'analise_atrasos_satisfacao.png',
        'resumo_executivo.txt'
    ]

    for file in files_to_zip:
        if os.path.exists(f'/content/{file}'):
            zipf.write(f'/content/{file}', file)

print("üì¶ Baixando ZIP com todos os resultados...")
files.download('/content/resultados_projeto_ia.zip')