{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ys8Zs3_Aum5",
        "outputId": "eb5251ba-2fdb-4f7a-d272-86f85b295de0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== PROJETO IA - AN√ÅLISE DE E-COMMERCE BRASILEIRO ===\n",
            "Autor: [SEU NOME]\n",
            "Data: 23/09/2025 19:08\n",
            "Disciplina: Intelig√™ncia Artificial - 7¬∫J SI\n",
            "============================================================\n",
            "\n",
            "üìÅ Carregando datasets...\n",
            "‚ùå Erro: [Errno 2] No such file or directory: '/content/olist_customers_dataset.csv'\n",
            "\n",
            "üîç INSTRU√á√ïES:\n",
            "1. Fa√ßa upload dos arquivos CSV para /content/\n",
            "2. Ou use: from google.colab import files; files.upload()\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# PROJETO IA - AN√ÅLISE DE ATRASOS E SATISFA√á√ÉO NO E-COMMERCE BRASILEIRO\n",
        "# Membros: Pedro Gabriel Marotta Silva - RA: 10418073 / Agozie Nunes Emehelu RA:10403570\n",
        "# Dataset: Brazilian E-Commerce Public Dataset by Olist\n",
        "# Objetivo: Processar dados para an√°lise de atrasos de entrega e reviews (N1)\n",
        "# =============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configurar visualiza√ß√µes\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"=== PROJETO IA - AN√ÅLISE DE E-COMMERCE BRASILEIRO ===\")\n",
        "print(\"Autor: [Pedro Gabriel Marotta Silva e Agozie Nunes Emehelu]\")\n",
        "print(\"Data:\", datetime.now().strftime(\"%d/%m/%Y %H:%M\"))\n",
        "print(\"Disciplina: Intelig√™ncia Artificial - 7¬∫J SI\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# =============================================================================\n",
        "# 1. CARREGAR DADOS\n",
        "# =============================================================================\n",
        "\n",
        "def load_olist_data():\n",
        "    \"\"\"\n",
        "    Carrega todos os datasets do Olist do diret√≥rio /content/\n",
        "    Retorna dicion√°rio com todos os DataFrames\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(\"\\nüìÅ Carregando datasets...\")\n",
        "\n",
        "        data = {}\n",
        "        files = {\n",
        "            'customers': 'olist_customers_dataset.csv',\n",
        "            'geolocation': 'olist_geolocation_dataset.csv',\n",
        "            'order_items': 'olist_order_items_dataset.csv',\n",
        "            'order_payments': 'olist_order_payments_dataset.csv',\n",
        "            'order_reviews': 'olist_order_reviews_dataset.csv',\n",
        "            'orders': 'olist_orders_dataset.csv',\n",
        "            'products': 'olist_products_dataset.csv',\n",
        "            'sellers': 'olist_sellers_dataset.csv',\n",
        "            'category_translation': 'product_category_name_translation.csv'\n",
        "        }\n",
        "\n",
        "        for key, filename in files.items():\n",
        "            data[key] = pd.read_csv(f'/content/{filename}')\n",
        "            print(f\"‚úÖ {filename}: {len(data[key])} registros\")\n",
        "\n",
        "        print(f\"\\nüéâ Total: {len(data)} datasets carregados com sucesso!\")\n",
        "        return data\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"‚ùå Erro: {e}\")\n",
        "        print(\"\\nüîç INSTRU√á√ïES:\")\n",
        "        print(\"1. Fa√ßa upload dos arquivos CSV para /content/\")\n",
        "        print(\"2. Ou use: from google.colab import files; files.upload()\")\n",
        "        return None\n",
        "\n",
        "# =============================================================================\n",
        "# 2. AN√ÅLISE EXPLORAT√ìRIA INICIAL\n",
        "# =============================================================================\n",
        "\n",
        "def exploratory_analysis(data):\n",
        "    \"\"\"\n",
        "    Realiza an√°lise explorat√≥ria inicial dos dados\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üìä AN√ÅLISE EXPLORAT√ìRIA INICIAL\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    summary_data = []\n",
        "\n",
        "    for name, df in data.items():\n",
        "        missing_pct = (df.isnull().sum().sum() / (len(df) * len(df.columns))) * 100\n",
        "\n",
        "        print(f\"\\nüìã Dataset: {name.upper()}\")\n",
        "        print(f\"   ‚Ä¢ Linhas: {len(df):,}\")\n",
        "        print(f\"   ‚Ä¢ Colunas: {len(df.columns)}\")\n",
        "        print(f\"   ‚Ä¢ Dados faltantes: {missing_pct:.1f}%\")\n",
        "        print(f\"   ‚Ä¢ Colunas: {', '.join(df.columns[:5])}{'...' if len(df.columns) > 5 else ''}\")\n",
        "\n",
        "        summary_data.append({\n",
        "            'Dataset': name,\n",
        "            'Registros': len(df),\n",
        "            'Colunas': len(df.columns),\n",
        "            'Missing_Pct': round(missing_pct, 1)\n",
        "        })\n",
        "\n",
        "    # Criar resumo\n",
        "    summary_df = pd.DataFrame(summary_data)\n",
        "    summary_df.to_csv('/content/dataset_summary.csv', index=False)\n",
        "\n",
        "    return summary_df\n",
        "\n",
        "# =============================================================================\n",
        "# 3. PROCESSAMENTO PRINCIPAL - ATRASOS E REVIEWS\n",
        "# =============================================================================\n",
        "\n",
        "def process_delivery_analysis(data):\n",
        "    \"\"\"\n",
        "    Processa dados para an√°lise de atrasos de entrega e satisfa√ß√£o\n",
        "    Foco: identificar padr√µes de atraso e impacto nas avalia√ß√µes\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üîÑ PROCESSANDO DADOS PARA AN√ÅLISE DE ATRASOS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    orders = data['orders'].copy()\n",
        "    reviews = data['order_reviews'].copy()\n",
        "\n",
        "    # 1. Processar datas\n",
        "    print(\"\\nüìÖ Processando datas...\")\n",
        "    date_cols = ['order_purchase_timestamp', 'order_approved_at',\n",
        "                'order_delivered_carrier_date', 'order_delivered_customer_date',\n",
        "                'order_estimated_delivery_date']\n",
        "\n",
        "    for col in date_cols:\n",
        "        if col in orders.columns:\n",
        "            orders[col] = pd.to_datetime(orders[col], errors='coerce')\n",
        "\n",
        "    # 2. Calcular m√©tricas de entrega\n",
        "    print(\"‚è∞ Calculando m√©tricas de tempo...\")\n",
        "\n",
        "    # Tempo total de entrega (compra ‚Üí entrega)\n",
        "    orders['delivery_time_days'] = (\n",
        "        orders['order_delivered_customer_date'] - orders['order_purchase_timestamp']\n",
        "    ).dt.days\n",
        "\n",
        "    # Atraso em dias (real vs estimado)\n",
        "    orders['delay_days'] = (\n",
        "        orders['order_delivered_customer_date'] - orders['order_estimated_delivery_date']\n",
        "    ).dt.days\n",
        "\n",
        "    # Classificar atraso\n",
        "    orders['delay_category'] = orders['delay_days'].apply(\n",
        "        lambda x: 'Muito Atrasado' if x > 7 else\n",
        "                 'Atrasado' if x > 0 else\n",
        "                 'No Prazo' if x >= -3 else\n",
        "                 'Antecipado' if not pd.isna(x) else 'Sem Info'\n",
        "    )\n",
        "\n",
        "    # 3. Merge com reviews\n",
        "    print(\"üîó Conectando com avalia√ß√µes...\")\n",
        "    delivery_analysis = pd.merge(\n",
        "        orders[['order_id', 'order_status', 'delivery_time_days', 'delay_days', 'delay_category']],\n",
        "        reviews[['order_id', 'review_score', 'review_comment_message']],\n",
        "        on='order_id',\n",
        "        how='left'\n",
        "    )\n",
        "\n",
        "    # 4. Filtrar apenas pedidos entregues com dados completos\n",
        "    delivery_analysis = delivery_analysis[\n",
        "        (delivery_analysis['order_status'] == 'delivered') &\n",
        "        (delivery_analysis['delay_days'].notna()) &\n",
        "        (delivery_analysis['review_score'].notna())\n",
        "    ].copy()\n",
        "\n",
        "    print(f\"‚úÖ Dataset final: {len(delivery_analysis):,} pedidos com dados completos\")\n",
        "\n",
        "    return delivery_analysis\n",
        "\n",
        "# =============================================================================\n",
        "# 4. AN√ÅLISES ESTAT√çSTICAS PARA O RELAT√ìRIO\n",
        "# =============================================================================\n",
        "\n",
        "def generate_report_statistics(delivery_data):\n",
        "    \"\"\"\n",
        "    Gera estat√≠sticas essenciais para o relat√≥rio N1\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üìà GERANDO ESTAT√çSTICAS PARA RELAT√ìRIO\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    # 1. ESTAT√çSTICAS GERAIS\n",
        "    print(\"\\n1Ô∏è‚É£ Estat√≠sticas Gerais:\")\n",
        "    total_orders = len(delivery_data)\n",
        "    avg_delivery_time = delivery_data['delivery_time_days'].mean()\n",
        "    avg_delay = delivery_data['delay_days'].mean()\n",
        "    avg_review_score = delivery_data['review_score'].mean()\n",
        "\n",
        "    general_stats = {\n",
        "        'total_pedidos': total_orders,\n",
        "        'tempo_entrega_medio_dias': round(avg_delivery_time, 1),\n",
        "        'atraso_medio_dias': round(avg_delay, 1),\n",
        "        'nota_media_review': round(avg_review_score, 2)\n",
        "    }\n",
        "\n",
        "    for key, value in general_stats.items():\n",
        "        print(f\"   ‚Ä¢ {key}: {value:,}\")\n",
        "\n",
        "    results['general_stats'] = pd.DataFrame([general_stats])\n",
        "\n",
        "    # 2. AN√ÅLISE POR CATEGORIA DE ATRASO\n",
        "    print(\"\\n2Ô∏è‚É£ An√°lise por Categoria de Atraso:\")\n",
        "    delay_analysis = delivery_data.groupby('delay_category').agg({\n",
        "        'order_id': 'count',\n",
        "        'review_score': ['mean', 'std'],\n",
        "        'delay_days': ['mean', 'min', 'max']\n",
        "    }).round(2)\n",
        "\n",
        "    delay_analysis.columns = ['qtd_pedidos', 'review_media', 'review_std',\n",
        "                             'delay_medio', 'delay_min', 'delay_max']\n",
        "    delay_analysis['percentual'] = (delay_analysis['qtd_pedidos'] / total_orders * 100).round(1)\n",
        "\n",
        "    print(delay_analysis)\n",
        "    results['delay_analysis'] = delay_analysis\n",
        "\n",
        "    # 3. CORRELA√á√ÉO ATRASO vs SATISFA√á√ÉO\n",
        "    print(\"\\n3Ô∏è‚É£ Correla√ß√£o Atraso vs Satisfa√ß√£o:\")\n",
        "    correlation = delivery_data['delay_days'].corr(delivery_data['review_score'])\n",
        "    print(f\"   ‚Ä¢ Correla√ß√£o delay_days vs review_score: {correlation:.3f}\")\n",
        "\n",
        "    # 4. DISTRIBUI√á√ÉO DE REVIEWS POR FAIXA DE ATRASO\n",
        "    print(\"\\n4Ô∏è‚É£ Reviews por Faixa de Atraso:\")\n",
        "    review_distribution = pd.crosstab(\n",
        "        delivery_data['delay_category'],\n",
        "        delivery_data['review_score'],\n",
        "        normalize='index'\n",
        "    ).round(3) * 100\n",
        "\n",
        "    print(\"Distribui√ß√£o percentual de notas por categoria:\")\n",
        "    print(review_distribution)\n",
        "    results['review_distribution'] = review_distribution\n",
        "\n",
        "    # 5. ESTAT√çSTICAS PARA MODELAGEM (N2)\n",
        "    print(\"\\n5Ô∏è‚É£ Preparando para Modelagem:\")\n",
        "\n",
        "    # Criar target bin√°rio para classifica√ß√£o: review ruim (1-3) vs boa (4-5)\n",
        "    delivery_data['review_ruim'] = (delivery_data['review_score'] <= 3).astype(int)\n",
        "\n",
        "    # Estat√≠sticas do target\n",
        "    review_ruim_stats = delivery_data['review_ruim'].value_counts()\n",
        "    print(f\"   ‚Ä¢ Reviews ruins (1-3): {review_ruim_stats[1]:,} ({review_ruim_stats[1]/len(delivery_data)*100:.1f}%)\")\n",
        "    print(f\"   ‚Ä¢ Reviews boas (4-5): {review_ruim_stats[0]:,} ({review_ruim_stats[0]/len(delivery_data)*100:.1f}%)\")\n",
        "\n",
        "    results['model_target_stats'] = pd.DataFrame({\n",
        "        'categoria': ['Review Ruim (1-3)', 'Review Boa (4-5)'],\n",
        "        'quantidade': [review_ruim_stats[1], review_ruim_stats[0]],\n",
        "        'percentual': [review_ruim_stats[1]/len(delivery_data)*100,\n",
        "                      review_ruim_stats[0]/len(delivery_data)*100]\n",
        "    })\n",
        "\n",
        "    return results, delivery_data\n",
        "\n",
        "# =============================================================================\n",
        "# 5. VISUALIZA√á√ïES PARA O RELAT√ìRIO\n",
        "# =============================================================================\n",
        "\n",
        "def create_visualizations(delivery_data, results):\n",
        "    \"\"\"\n",
        "    Cria visualiza√ß√µes essenciais para o relat√≥rio\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üìä CRIANDO VISUALIZA√á√ïES\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "    fig.suptitle('An√°lise de Atrasos e Satisfa√ß√£o - E-commerce Brasileiro', fontsize=16, fontweight='bold')\n",
        "\n",
        "    # 1. Distribui√ß√£o de Atrasos\n",
        "    axes[0,0].hist(delivery_data['delay_days'], bins=50, edgecolor='black', alpha=0.7)\n",
        "    axes[0,0].axvline(0, color='red', linestyle='--', label='Prazo Estimado')\n",
        "    axes[0,0].set_title('Distribui√ß√£o de Atrasos de Entrega')\n",
        "    axes[0,0].set_xlabel('Atraso (dias)')\n",
        "    axes[0,0].set_ylabel('Frequ√™ncia')\n",
        "    axes[0,0].legend()\n",
        "    axes[0,0].grid(True, alpha=0.3)\n",
        "\n",
        "    # 2. Review Score por Categoria de Atraso\n",
        "    delay_review = delivery_data.groupby('delay_category')['review_score'].mean().sort_values()\n",
        "    axes[0,1].bar(range(len(delay_review)), delay_review.values, color='skyblue', edgecolor='black')\n",
        "    axes[0,1].set_xticks(range(len(delay_review)))\n",
        "    axes[0,1].set_xticklabels(delay_review.index, rotation=45)\n",
        "    axes[0,1].set_title('Nota M√©dia por Categoria de Atraso')\n",
        "    axes[0,1].set_ylabel('Review Score M√©dio')\n",
        "    axes[0,1].grid(True, alpha=0.3)\n",
        "\n",
        "    # 3. Correla√ß√£o Atraso vs Review\n",
        "    axes[1,0].scatter(delivery_data['delay_days'], delivery_data['review_score'],\n",
        "                     alpha=0.5, s=1, color='coral')\n",
        "    axes[1,0].set_title('Correla√ß√£o: Atraso vs Review Score')\n",
        "    axes[1,0].set_xlabel('Atraso (dias)')\n",
        "    axes[1,0].set_ylabel('Review Score')\n",
        "    axes[1,0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Linha de tend√™ncia\n",
        "    z = np.polyfit(delivery_data['delay_days'], delivery_data['review_score'], 1)\n",
        "    p = np.poly1d(z)\n",
        "    axes[1,0].plot(delivery_data['delay_days'], p(delivery_data['delay_days']),\n",
        "                  \"r--\", alpha=0.8, linewidth=2)\n",
        "\n",
        "    # 4. Distribui√ß√£o de Review Scores\n",
        "    review_counts = delivery_data['review_score'].value_counts().sort_index()\n",
        "    axes[1,1].bar(review_counts.index, review_counts.values, color='lightgreen', edgecolor='black')\n",
        "    axes[1,1].set_title('Distribui√ß√£o de Review Scores')\n",
        "    axes[1,1].set_xlabel('Review Score')\n",
        "    axes[1,1].set_ylabel('Quantidade')\n",
        "    axes[1,1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/analise_atrasos_satisfacao.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"‚úÖ Gr√°fico salvo como: analise_atrasos_satisfacao.png\")\n",
        "\n",
        "# =============================================================================\n",
        "# 6. EXPORTAR RESULTADOS\n",
        "# =============================================================================\n",
        "\n",
        "def export_results(delivery_data, results):\n",
        "    \"\"\"\n",
        "    Exporta todos os resultados em arquivos CSV para uso no relat√≥rio\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üíæ EXPORTANDO RESULTADOS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # 1. Dataset principal processado\n",
        "    delivery_data.to_csv('/content/dataset_processado_atrasos.csv', index=False)\n",
        "    print(\"‚úÖ dataset_processado_atrasos.csv\")\n",
        "\n",
        "    # 2. Estat√≠sticas gerais\n",
        "    results['general_stats'].to_csv('/content/estatisticas_gerais.csv', index=False)\n",
        "    print(\"‚úÖ estatisticas_gerais.csv\")\n",
        "\n",
        "    # 3. An√°lise por categoria de atraso\n",
        "    results['delay_analysis'].to_csv('/content/analise_por_categoria_atraso.csv')\n",
        "    print(\"‚úÖ analise_por_categoria_atraso.csv\")\n",
        "\n",
        "    # 4. Distribui√ß√£o de reviews\n",
        "    results['review_distribution'].to_csv('/content/distribuicao_reviews_por_atraso.csv')\n",
        "    print(\"‚úÖ distribuicao_reviews_por_atraso.csv\")\n",
        "\n",
        "    # 5. Stats para modelagem\n",
        "    results['model_target_stats'].to_csv('/content/target_modelagem_stats.csv', index=False)\n",
        "    print(\"‚úÖ target_modelagem_stats.csv\")\n",
        "\n",
        "    # 6. Resumo executivo para relat√≥rio\n",
        "    summary_report = f\"\"\"\n",
        "RESUMO EXECUTIVO - AN√ÅLISE DE ATRASOS E SATISFA√á√ÉO\n",
        "Dataset: Brazilian E-Commerce Public Dataset by Olist\n",
        "Data da An√°lise: {datetime.now().strftime(\"%d/%m/%Y %H:%M\")}\n",
        "\n",
        "PRINCIPAIS DESCOBERTAS:\n",
        "‚Ä¢ Total de pedidos analisados: {len(delivery_data):,}\n",
        "‚Ä¢ Tempo m√©dio de entrega: {delivery_data['delivery_time_days'].mean():.1f} dias\n",
        "‚Ä¢ Atraso m√©dio: {delivery_data['delay_days'].mean():.1f} dias\n",
        "‚Ä¢ Nota m√©dia geral: {delivery_data['review_score'].mean():.2f}\n",
        "‚Ä¢ Correla√ß√£o atraso vs satisfa√ß√£o: {delivery_data['delay_days'].corr(delivery_data['review_score']):.3f}\n",
        "\n",
        "DISTRIBUI√á√ÉO DE ATRASOS:\n",
        "{results['delay_analysis']['percentual'].to_string()}\n",
        "\n",
        "IMPACTO NA SATISFA√á√ÉO:\n",
        "‚Ä¢ Reviews ruins (1-3): {(delivery_data['review_score'] <= 3).sum():,} ({(delivery_data['review_score'] <= 3).mean()*100:.1f}%)\n",
        "‚Ä¢ Reviews boas (4-5): {(delivery_data['review_score'] >= 4).sum():,} ({(delivery_data['review_score'] >= 4).mean()*100:.1f}%)\n",
        "\n",
        "RECOMENDA√á√ïES PARA MODELAGEM (N2):\n",
        "1. Usar 'delay_days' como feature principal para previs√£o de atraso\n",
        "2. Target bin√°rio: review_ruim (score 1-3) vs review_boa (score 4-5)\n",
        "3. Features adicionais: delivery_time_days, sazonalidade, geolocaliza√ß√£o\n",
        "4. Algoritmos sugeridos: Random Forest, Gradient Boosting, Logistic Regression\n",
        "    \"\"\"\n",
        "\n",
        "    with open('/content/resumo_executivo.txt', 'w', encoding='utf-8') as f:\n",
        "        f.write(summary_report)\n",
        "    print(\"‚úÖ resumo_executivo.txt\")\n",
        "\n",
        "    print(f\"\\nüéâ Todos os arquivos exportados para /content/\")\n",
        "    print(\"üìÅ Arquivos gerados:\")\n",
        "    print(\"   ‚Ä¢ dataset_processado_atrasos.csv (dados limpos para N2)\")\n",
        "    print(\"   ‚Ä¢ estatisticas_gerais.csv (n√∫meros-chave)\")\n",
        "    print(\"   ‚Ä¢ analise_por_categoria_atraso.csv (tabela principal)\")\n",
        "    print(\"   ‚Ä¢ distribuicao_reviews_por_atraso.csv (crosstab)\")\n",
        "    print(\"   ‚Ä¢ target_modelagem_stats.csv (balanceamento do target)\")\n",
        "    print(\"   ‚Ä¢ analise_atrasos_satisfacao.png (gr√°ficos)\")\n",
        "    print(\"   ‚Ä¢ resumo_executivo.txt (s√≠ntese para relat√≥rio)\")\n",
        "\n",
        "# =============================================================================\n",
        "# 7. EXECU√á√ÉO PRINCIPAL\n",
        "# =============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Fun√ß√£o principal - executa todo o pipeline de an√°lise\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 1. Carregar dados\n",
        "        data = load_olist_data()\n",
        "        if data is None:\n",
        "            return\n",
        "\n",
        "        # 2. An√°lise explorat√≥ria\n",
        "        summary = exploratory_analysis(data)\n",
        "\n",
        "        # 3. Processamento principal\n",
        "        delivery_data = process_delivery_analysis(data)\n",
        "\n",
        "        # 4. Estat√≠sticas para relat√≥rio\n",
        "        results, delivery_data_final = generate_report_statistics(delivery_data)\n",
        "\n",
        "        # 5. Visualiza√ß√µes\n",
        "        create_visualizations(delivery_data_final, results)\n",
        "\n",
        "        # 6. Exportar resultados\n",
        "        export_results(delivery_data_final, results)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"üéâ AN√ÅLISE CONCLU√çDA COM SUCESSO!\")\n",
        "        print(\"=\"*60)\n",
        "        print(\"‚úÖ Dados processados e exportados\")\n",
        "        print(\"‚úÖ Visualiza√ß√µes criadas\")\n",
        "        print(\"‚úÖ Relat√≥rios gerados\")\n",
        "        print(\"\\nüìù Pr√≥ximos passos:\")\n",
        "        print(\"1. Baixe os arquivos CSV gerados\")\n",
        "        print(\"2. Use os dados no seu relat√≥rio N1\")\n",
        "        print(\"3. Para N2: implemente modelos de ML com dataset_processado_atrasos.csv\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro durante execu√ß√£o: {e}\")\n",
        "        print(\"üîç Verifique se todos os arquivos CSV foram carregados corretamente\")\n",
        "\n",
        "# EXECUTAR AN√ÅLISE\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute para baixar todos os arquivos gerados\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "\n",
        "# Criar ZIP com todos os resultados\n",
        "with zipfile.ZipFile('/content/resultados_projeto_ia.zip', 'w') as zipf:\n",
        "    files_to_zip = [\n",
        "        'dataset_processado_atrasos.csv',\n",
        "        'estatisticas_gerais.csv',\n",
        "        'analise_por_categoria_atraso.csv',\n",
        "        'distribuicao_reviews_por_atraso.csv',\n",
        "        'target_modelagem_stats.csv',\n",
        "        'analise_atrasos_satisfacao.png',\n",
        "        'resumo_executivo.txt'\n",
        "    ]\n",
        "\n",
        "    for file in files_to_zip:\n",
        "        if os.path.exists(f'/content/{file}'):\n",
        "            zipf.write(f'/content/{file}', file)\n",
        "\n",
        "print(\"üì¶ Baixando ZIP com todos os resultados...\")\n",
        "files.download('/content/resultados_projeto_ia.zip')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Ht1Aks1qIoKq",
        "outputId": "c7166a06-7a5c-4b5e-d517-027bf2b5612e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'os' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2806727047.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles_to_zip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'/content/{file}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mzipf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'/content/{file}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ]
    }
  ]
}